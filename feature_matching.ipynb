{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import plot_matches"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and preprocess images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def crop_center(img, h_ratio=0.5, w_ratio=0.4):\n",
    "    h, w = img.shape[:2]\n",
    "    return img[int((1 - h_ratio) / 2 * h):int((1 + h_ratio) / 2 * h), int((1 - w_ratio) / 2 * w):int((1 + w_ratio) / 2 * w)]\n",
    "\n",
    "\n",
    "imgs = [crop_center(imread(f'test/microwave/img{i:06}.png')) for i in range(35, 39)]\n",
    "plt.figure(figsize=(40, 10))\n",
    "for i, img in enumerate(imgs):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'img{i}')\n",
    "    plt.imshow(imgs[i])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Convert to grayscale\n",
    "# imgs = [rgb2gray(img) for img in imgs]\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# for i, img in enumerate(imgs):\n",
    "#     plt.subplot(1, 3, i + 1)\n",
    "#     plt.imshow(imgs[i], cmap='gray')\n",
    "#     plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detect features and plot matches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def extract_correspondences(im1, im2, feature='sift', coeff=0.7):\n",
    "    feature_extractor = cv2.SIFT_create() if feature=='sift' else cv2.ORB_create()\n",
    "    kp1, des1 = feature_extractor.detectAndCompute(im1, None)\n",
    "    kp2, des2 = feature_extractor.detectAndCompute(im2, None)\n",
    "    matches = cv2.BFMatcher().knnMatch(des1, des2, k=2)\n",
    "    matches = [[m] for m, n in matches if 0.1 * n.distance < m.distance < coeff * n.distance]\n",
    "    pts1 = np.array([kp1[match[0].queryIdx].pt for match in matches])\n",
    "    pts2 = np.array([kp2[match[0].trainIdx].pt for match in matches])\n",
    "    return pts1, pts2, matches, kp1, kp2\n",
    "\n",
    "for i in range(1, len(imgs)):\n",
    "    _, _, matches_for_plot, kp1, kp2 = extract_correspondences(imgs[0], imgs[i])\n",
    "    img = cv2.drawMatchesKnn(imgs[0], kp1, imgs[i], kp2, matches_for_plot, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(40, 15))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Correspondences between img0 and img{i} using SIFT feature matching')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# pts1, pts2, matches_for_plot, kp1, kp2 = extract_correspondences(imgs[0], imgs[1], feature='orb', coeff=0.9)\n",
    "# img = cv2.drawMatchesKnn(imgs[0], kp1, imgs[1], kp2, matches_for_plot, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# plt.axis('off')\n",
    "# plt.title('Correspondences using ORB feature matching')\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pybullet': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "7b7e832203cb5d25565136e8df82b99148ff5565936a14fa96b8d75db192acd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}